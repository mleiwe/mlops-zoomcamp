{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow practice\n",
    "This notebook aims to help you get familiar with using MLflow through hands-on learning by training various models to predict the duration of a taxi ride.\n",
    "\n",
    "**Data**\n",
    "I'm taking the [NYC taxi cab data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) which is store in parquet format.\n",
    "\n",
    "Specifically I will take the green taxi cab data from Jan 2023 (train), Feb 2023(val), and Mar 2023 (test)\n",
    "\n",
    "The data will be stored in the following folder `/mlops-zoomcamp/cohorts/2024/02-experiment-tracking/homework/data/`\n",
    "\n",
    "The data dictionary is available [here](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_green.pdf)\n",
    "\n",
    "**Models**\n",
    "While technically not necessary for learning. I'm going to test 3 different models\n",
    "1. xgboost\n",
    "2. random forrest (sklearn)\n",
    "3. linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import mlflow\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set paths\n",
    "Homework_Path = os.getcwd()\n",
    "Data_Path = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "# Download data - I did this in the terminal because I forgot to install wget. But this should work\n",
    "os.chdir(Data_Path)\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-01.parquet\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-03.parquet\n",
    "os.listdir()\n",
    "os.chdir(Homework_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:25:10</td>\n",
       "      <td>2023-03-01 00:35:47</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82</td>\n",
       "      <td>196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:14:29</td>\n",
       "      <td>2023-03-01 00:25:04</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-9.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:14:29</td>\n",
       "      <td>2023-03-01 00:25:04</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-28 22:59:46</td>\n",
       "      <td>2023-02-28 23:08:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:54:03</td>\n",
       "      <td>2023-03-01 01:03:14</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236</td>\n",
       "      <td>229</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.14</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2023-03-01 00:25:10   2023-03-01 00:35:47                  N   \n",
       "1         2  2023-03-01 00:14:29   2023-03-01 00:25:04                  N   \n",
       "2         2  2023-03-01 00:14:29   2023-03-01 00:25:04                  N   \n",
       "3         2  2023-02-28 22:59:46   2023-02-28 23:08:38                  N   \n",
       "4         2  2023-03-01 00:54:03   2023-03-01 01:03:14                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0            82           196              1.0           2.36   \n",
       "1         1.0             7             7              1.0           0.78   \n",
       "2         1.0             7             7              1.0           0.78   \n",
       "3         1.0           166            74              1.0           1.66   \n",
       "4         1.0           236           229              1.0           3.14   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         13.5    1.0      0.5        0.00           0.0        NaN   \n",
       "1         -6.5   -1.0     -0.5        0.00           0.0        NaN   \n",
       "2          6.5    1.0      0.5        0.00           0.0        NaN   \n",
       "3         11.4    1.0      0.5        2.78           0.0        NaN   \n",
       "4         15.6    1.0      0.5        4.17           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    1.0         16.00           2.0        1.0   \n",
       "1                   -1.0         -9.00           3.0        1.0   \n",
       "2                    1.0          9.00           3.0        1.0   \n",
       "3                    1.0         16.68           1.0        1.0   \n",
       "4                    1.0         25.02           1.0        1.0   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                  0.00  \n",
       "1                  0.00  \n",
       "2                  0.00  \n",
       "3                  0.00  \n",
       "4                  2.75  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"./data/green_tripdata_2023-01.parquet\"\n",
    "val_path = \"./data/green_tripdata_2023-02.parquet\"\n",
    "test_path = \"./data/green_tripdata_2023-03.parquet\"\n",
    "\n",
    "df_train = pd.read_parquet(train_path)\n",
    "df_val = pd.read_parquet(val_path)\n",
    "df_test = pd.read_parquet(test_path)\n",
    "\n",
    "df_train.head()\n",
    "df_val.head()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data\n",
    "Ok, so I want to make a slightly more complicated data set than those used in the tutorials. Here are the steps I want to do\n",
    "\n",
    "**Create the dataframe and features**\n",
    "`create_dataframe`\n",
    "1. Create the target variable (dropoff - pickup = duration)\n",
    "    * Filter out any data with a duration < 1min and >60 mins\n",
    "2. Convert pickup and dropoff locations into strings\n",
    "3. Create additional columns for day of the week: 1-7 (Mon-Sun, ordinal)\n",
    "4. Create columns for hours and minutes of pick up\n",
    "\n",
    "**Preprocess the dataframe**\n",
    "`preprocess_dataframe`\n",
    "1. Merge the pickup and dropoff to a single string\n",
    "2. Use the dictionary vectorizer to one-hot encode the PU_DO location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def create_dataframe(filepath):\n",
    "    #Read the parquet file\n",
    "    df = pd.read_parquet(train_path)\n",
    "\n",
    "    # Create duration (mins)\n",
    "    df['duration'] = df['lpep_dropoff_datetime'] - df['lpep_pickup_datetime']\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    # Filter outliers\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    #Pick up and drop off locations to strings\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    #Additional features\n",
    "    df['pickup_day'] = df.lpep_pickup_datetime.apply(lambda x: x.weekday())\n",
    "    df['pickup_hour'] = df.lpep_pickup_datetime.apply(lambda x: x.hour)\n",
    "    df['pickup_min'] = df.lpep_pickup_datetime.apply(lambda x: x.minute)\n",
    "\n",
    "    #Remove unwanted columns\n",
    "    chosen_cols = ['duration','PULocationID','DOLocationID','trip_distance','pickup_day','pickup_hour','pickup_min']\n",
    "    df = df[chosen_cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_dataframe(df: pd.DataFrame, dv: DictVectorizer, fit_dv: bool = False):\n",
    "    #Merge the Pickup and dropoff locations to a single column\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "\n",
    "    numerical = ['trip_distance','pickup_day','pickup_hour','pickup_min']\n",
    "    \n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    if fit_dv:\n",
    "        X = dv.fit_transform(dicts)\n",
    "    else:\n",
    "        X = dv.transform(dicts)\n",
    "    return X, dv\n",
    "\n",
    "def dump_pickle(obj, filename: str):\n",
    "    with open(filename, \"wb\") as f_out:\n",
    "        return pickle.dump(obj, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train contains: 65946 entries, and 5705 columns\n",
      "X_val contains: 65946 entries, and 5705 columns\n",
      "X_test contains: 65946 entries, and 5705 columns\n"
     ]
    }
   ],
   "source": [
    "dv = DictVectorizer()\n",
    "\n",
    "df_train = create_dataframe(train_path)\n",
    "df_val = create_dataframe(val_path)\n",
    "df_test = create_dataframe(test_path)\n",
    "\n",
    "X_train, dv = preprocess_dataframe(df_train,dv, fit_dv=True)\n",
    "X_val, _ = preprocess_dataframe(df_val,dv, fit_dv=False)\n",
    "X_test, _ = preprocess_dataframe(df_test,dv, fit_dv=False)\n",
    "\n",
    "print(f\"X_train contains: {np.shape(X_train)[0]} entries, and {np.shape(X_train)[1]} columns\")\n",
    "print(f\"X_val contains: {np.shape(X_val)[0]} entries, and {np.shape(X_val)[1]} columns\")\n",
    "print(f\"X_test contains: {np.shape(X_test)[0]} entries, and {np.shape(X_test)[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store target variables\n",
    "y_train = df_train['duration']\n",
    "y_val = df_val['duration']\n",
    "y_test = df_test['duration']\n",
    "\n",
    "# Save DictVectorizer and datasets\n",
    "dump_pickle(dv, os.path.join(Data_Path, \"dv.pkl\"))\n",
    "dump_pickle((X_train, y_train), os.path.join(Data_Path, \"train.pkl\"))\n",
    "dump_pickle((X_val, y_val), os.path.join(Data_Path, \"val.pkl\"))\n",
    "dump_pickle((X_test, y_test), os.path.join(Data_Path, \"test.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "So in this experiment (`nyc-taxi-ride-prediction`) the aim is to investigate which model can best predict the duration of a taxi ride. \n",
    "\n",
    "I'm planning three demonstrations\n",
    "1. Record a single run (more for practice)\n",
    "2. Perform a thorough experiment, with hyperparameter optimisation\n",
    "3. Evaluate multiple models, and then select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record a single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/marcusleiwe/Documents/GitHubRepos/mlops-zoomcamp/cohorts/2024/02-experiment-tracking/homework/mlruns/1', creation_time=1716887585182, experiment_id='1', last_update_time=1716887585182, lifecycle_stage='active', name='nyc-taxi-ride-prediction-single', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure MLflow\n",
    "database_uri = \"sqlite:///mlflow.db\"\n",
    "experiment_name = \"nyc-taxi-ride-prediction-single\"\n",
    "\n",
    "mlflow.set_tracking_uri(database_uri) #The name of the database to use\n",
    "mlflow.set_experiment(experiment_name) #If already exists mlflow will append to existing data. Else it will make a new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlops_zoomcamp/lib/python3.9/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Train the model\n",
    "with mlflow.start_run():\n",
    "    #MLflow tags\n",
    "    mlflow.set_tag(\"developer\",\"Marcus\")\n",
    "    mlflow.log_param(\"train-data-path\",train_path)\n",
    "    mlflow.log_param(\"val-data-path\",val_path)\n",
    "\n",
    "    #Model init\n",
    "    params = {\n",
    "        'max_depth': 15,\n",
    "        'n_estimators': 50,\n",
    "        'min_samples_split': 2,\n",
    "        'min_samples_leaf': 4,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    #Store Random Forest Parameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    #Actually train the model\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "\n",
    "    #Evaluation\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\",rmse)\n",
    "\n",
    "    #Save model\n",
    "    with open('./models/rf_reg.bin','wb') as f_out:\n",
    "        pickle.dump((dv,rf), f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Tracking with Hyperparameter Tuning\n",
    "In this case I will optimise the random forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/28 18:17:33 INFO mlflow.tracking.fluent: Experiment with name 'nyc-taxi-ride-prediction-optimisation' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/marcusleiwe/Documents/GitHubRepos/mlops-zoomcamp/cohorts/2024/02-experiment-tracking/homework/mlruns/2', creation_time=1716891453739, experiment_id='2', last_update_time=1716891453739, lifecycle_stage='active', name='nyc-taxi-ride-prediction-optimisation', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure MLflow\n",
    "database_uri = \"sqlite:///mlflow.db\"\n",
    "experiment_name = \"nyc-taxi-ride-prediction-optimisation\"\n",
    "\n",
    "mlflow.set_tracking_uri(database_uri) #The name of the database to use\n",
    "mlflow.set_experiment(experiment_name) #If already exists mlflow will append to existing data. Else it will make a new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials    \n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "#Define the search space\n",
    "search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 2, 20, 1)),\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 5, 100, 5)),\n",
    "        #'min_samples_split': scope.int(hp.quniform('min_samples_split', 1, 10, 1)),\n",
    "        #'criterion' : hp.choice('criterion', ['squared_error', 'poisson']),\n",
    "        #'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        #Create tags\n",
    "        mlflow.set_tag(\"model\",\"RandomForestRegressor\")\n",
    "        mlflow.set_tag(\"developer\",\"Marcus\")\n",
    "        mlflow.log_param(\"train-data-path\",train_path)\n",
    "        mlflow.log_param(\"val-data-path\",val_path)\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        #Train model\n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        \n",
    "        #Evaluation\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlops_zoomcamp/lib/python3.9/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "\n",
      "job exception: 'NoneType' object is not iterable\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:15<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use fmin to optimise\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_result \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#the search space\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#uses the TPE algo to estimate the next parameters\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTrials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#Stores the information for each trial\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlops_zoomcamp/lib/python3.9/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlops_zoomcamp/lib/python3.9/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlops_zoomcamp/lib/python3.9/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlops_zoomcamp/lib/python3.9/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlops_zoomcamp/lib/python3.9/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlops_zoomcamp/lib/python3.9/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mlops_zoomcamp/lib/python3.9/site-packages/hyperopt/base.py:897\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 897\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     status \u001b[38;5;241m=\u001b[39m dict_rval[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m STATUS_STRINGS:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Use fmin to optimise\n",
    "rstate = np.random.default_rng(42)\n",
    "\n",
    "best_result = fmin(\n",
    "    fn = objective,\n",
    "    space = search_space, #the search space\n",
    "    algo = tpe.suggest, #uses the TPE algo to estimate the next parameters\n",
    "    max_evals = 10,\n",
    "    trials = Trials(), #Stores the information for each trial\n",
    "    rstate=rstate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 int\n",
      "1   float\n",
      "2     hyperopt_param\n",
      "3       Literal{max_depth}\n",
      "4       loguniform\n",
      "5         Literal{2}\n",
      "6         Literal{10}\n"
     ]
    }
   ],
   "source": [
    "print(scope.int(hp.loguniform('max_depth', 2, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
